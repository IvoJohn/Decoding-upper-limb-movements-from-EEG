{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Dense, LSTM, Dropout, Conv2D, Lambda, MaxPooling2D, Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n",
    "from EEGPipelineModule import read_gdf, create_epochs, downsampling_epochs, epochs_to_dataframe, filtering_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for dataframe preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_x_y(df):\n",
    "    x = df.set_index('time')\n",
    "    x.drop('epoch', axis=1, inplace=True)\n",
    "    y = pd.get_dummies(x.condition)\n",
    "    x.drop('condition', axis=1, inplace=True)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def x_to_3d(x):\n",
    "    scaler = MinMaxScaler()\n",
    "    x_scaled = pd.DataFrame(scaler.fit_transform(x), columns=x.columns, index=x.index)\n",
    "    x_3d = x_scaled.values.reshape((n_samples,-1,n_channels))\n",
    "    return x_3d\n",
    "\n",
    "\n",
    "\n",
    "def y_to_3d(y, window_size):\n",
    "    columns = list(y)\n",
    "    data = []\n",
    "\n",
    "    for i in range(window_size, y.shape[0], window_size):\n",
    "        values = y.iloc[i].values\n",
    "        zipped = zip(columns, values)\n",
    "        a_dictionary = dict(zipped)\n",
    "        data.append(a_dictionary)\n",
    "\n",
    "    \n",
    "    y_3d = y.loc[-199]\n",
    "    y_3d.append(data, True)\n",
    "    return y_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = ''\n",
    "\n",
    "event_id = {'1536': 1, '1537': 2, '1538': 3, '1539': 4, '1540': 5, '1541': 6, '1542': 7}\n",
    "\n",
    "event_dictionary = {'elow/flexion': 1, 'elbow/extension': 2, 'arm/supination': 3,\n",
    "              'arm/pronation': 4, 'hand/close': 5, 'hand/open': 6, 'rest': 7}\n",
    "tmin = -0.75\n",
    "tmax = 2\n",
    "\n",
    "l_freq = 50\n",
    "h_freq = 0.5\n",
    "\n",
    "sfreq=256\n",
    "\n",
    "n_samples = 42\n",
    "time_steps=50\n",
    "window_size = 704\n",
    "n_channels = 61\n",
    "n_classes = 7\n",
    "\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(LSTM(units=128, input_shape=(window_size, n_channels), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=32, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_history = {}\n",
    "for dir_name in tqdm(os.listdir(dir_path)[:1]):\n",
    "    for file_name in tqdm(os.listdir(os.path.join(dir_path, dir_name))[1:2]):\n",
    "        data_path = os.path.join(dir_path, dir_name, file_name)\n",
    "        data = read_gdf(data_path)\n",
    "        epochs = create_epochs(data=data, event_id=event_id, event_dictionary=event_dictionary, tmin=tmin, tmax=tmax)\n",
    "        filtered_epochs = filtering_epochs(epochs, l_freq=l_freq, h_freq=h_freq)\n",
    "        downsampled_epochs = downsampling_epochs(filtered_epochs, sfreq=sfreq)\n",
    "        dataframed_epochs = epochs_to_dataframe(downsampled_epochs)\n",
    "        X, y = df_to_x_y(dataframed_epochs)\n",
    "        X = x_to_3d(X)\n",
    "        y = y_to_3d(y, window_size=window_size)\n",
    "        model_history[file_name] = model.fit(X, y, batch_size=1, shuffle=True, epochs=n_epochs)\n",
    "    #if n_epochs > 4:\n",
    "        #n_epochs -= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_loss = []\n",
    "history_accuracy = []\n",
    "for key, value in model_history.items():\n",
    "    history_loss.append(value.history['loss'])\n",
    "    history_accuracy.append(value.history['accuracy'])\n",
    "    \n",
    "    \n",
    "plt.plot(history_loss, label='Loss')\n",
    "plt.title('Loss for training data')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history_accuracy, label='Accuracy')\n",
    "plt.title('Accuracy for training data')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "predictions = {}\n",
    "for dir_name in tqdm(os.listdir(dir_path)[-14:-13]):\n",
    "    for file_name in os.listdir(os.path.join(dir_path, dir_name)):\n",
    "        data_path = os.path.join(dir_path, dir_name, file_name)\n",
    "        data = read_gdf(data_path)\n",
    "        epochs = create_epochs(data=data, event_id=event_id, event_dictionary=event_dictionary, tmin=tmin, tmax=tmax)\n",
    "        filtered_epochs = filtering_epochs(epochs, l_freq=l_freq, h_freq=h_freq)\n",
    "        downsampled_epochs = downsampling_epochs(filtered_epochs, sfreq=sfreq)\n",
    "        dataframed_epochs = epochs_to_dataframe(downsampled_epochs)\n",
    "        X, y = df_to_x_y(dataframed_epochs)\n",
    "        X = x_to_3d(X)\n",
    "        y = y_to_3d(y, window_size=window_size)\n",
    "        results[file_name] = model.evaluate(X, y, batch_size=1)\n",
    "        predictions[file_name] = model.predict(X, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('EEG_10epochs_per_file')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mne]",
   "language": "python",
   "name": "conda-env-mne-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
